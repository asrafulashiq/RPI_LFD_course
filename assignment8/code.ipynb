{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Data loading and preprocessig ---------------------- #\n",
    "\n",
    "file_train = 'ZipDigits.train'\n",
    "file_test = 'ZipDigits.test'\n",
    "\n",
    "\n",
    "def read_data(file_name):\n",
    "    digits = []\n",
    "    images = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(' ')\n",
    "            line = [float(i) for i in line]\n",
    "            digit = int(line[0])\n",
    "            data = line[1:]\n",
    "            images.append(data)\n",
    "            digits.append(digit)\n",
    "    return np.array(images), np.array(digits)\n",
    "\n",
    "\n",
    "def get_features(file_name):\n",
    "    images, digits = read_data(file_name)\n",
    "    images = images.reshape(-1, 16, 16)\n",
    "    images = (images + 1) / 2  # normalize between [0,1]\n",
    "\n",
    "\n",
    "    # Extract feature\n",
    "    intensities = images.reshape(-1, 16 * 16).mean(axis=-1)\n",
    "    symmetry = np.power(images[..., ::-1] - images,\n",
    "                        2).reshape(images.shape[0], -1).mean(axis=-1)\n",
    "\n",
    "    ind_1 = (digits == 1)\n",
    "    ind_n1 = (digits != 1)\n",
    "    labels = np.zeros(digits.shape[0])\n",
    "    labels[ind_1] = 1\n",
    "    labels[ind_n1] = -1\n",
    "    features = np.concatenate((intensities[:, None], symmetry[:, None]),\n",
    "                              axis=1)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "# ------------------------------ train features ------------------------------ #\n",
    "features_train, labels_train = get_features(file_train)\n",
    "\n",
    "# ------------------------------- test features ------------------------------ #\n",
    "features_test, labels_test = get_features(file_test)\n",
    "\n",
    "# Combine the training and test data into a single data set.\n",
    "features = np.concatenate((features_train, features_test), axis=0)\n",
    "labels = np.concatenate((labels_train, labels_test), axis=0)\n",
    "\n",
    "# normalize features between [-1, 1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Randomly select 300 data points for your data set D. Put the remaining data into a test set Dtest\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, train_size=300, random_state=0)\n",
    "\n",
    "assert features_train.shape[0] == 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1)\n",
    "### Use the 8th order Legendre polynomial feature transform to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Z: 45\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import legendre\n",
    "\n",
    "# 0 1 2 3\n",
    "# 0 1 2 3\n",
    "\n",
    "# 1 + 2 + 3 + ... + (n+1) = (n+1)(n+2)/2\n",
    "\n",
    "\n",
    "def get_feat_transform_legenre(features, degree=8):\n",
    "    \"\"\"\n",
    "    Transform features using Legendre polynomial\n",
    "    \"\"\"\n",
    "    n_features = features.shape[1]\n",
    "    n_samples = features.shape[0]\n",
    "\n",
    "    x = features[:, 0]\n",
    "    y = features[:, 1]\n",
    "\n",
    "    n_features_transformed = int((degree + 1) * (degree + 2) / 2)\n",
    "    features_transformed = np.zeros((n_samples, n_features_transformed))\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(degree):\n",
    "        for j in range(degree):\n",
    "            if i + j <= degree:\n",
    "                features_transformed[:, counter] = legendre(i)(x) * legendre(j)(\n",
    "                    y)  # L_i(x) * L_j(y)\n",
    "                counter += 1\n",
    "\n",
    "    return features_transformed\n",
    "\n",
    "# get transformed features\n",
    "feat_tfm = get_feat_transform_legenre(features_train, degree=8)\n",
    "print(f\"Dimension of Z: {feat_tfm.shape[1]}\")\n",
    "\n",
    "feat_tfm_test = get_feat_transform_legenre(features_test, degree=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2)\n",
    "### Give a plot of the decision boundary for the resulting weights produced by the linear regression algorithm without any regularization (Î» = 0). Do you think there is overfitting or underfitting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9566666666666667\n",
      "Accuracy on test set: 0.953322960657924\n"
     ]
    }
   ],
   "source": [
    "Z = feat_tfm\n",
    "w_lin = np.linalg.pinv(Z.transpose() @ Z) @ Z.transpose() @ labels_train\n",
    "y_pred = np.sign(np.dot(Z, w_lin))\n",
    "acc_train = accuracy_score(labels_train, y_pred)\n",
    "\n",
    "# test error\n",
    "y_pred_test = np.sign(np.dot(feat_tfm_test, w_lin))\n",
    "acc_test = accuracy_score(labels_test, y_pred_test)\n",
    "\n",
    "print(f\"Accuracy on training set: {acc_train}\")\n",
    "print(f\"Accuracy on test set: {acc_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9533333333333334\n",
      "Accuracy on test set: 0.9633251833740831\n"
     ]
    }
   ],
   "source": [
    "Z = feat_tfm\n",
    "lamb = 2\n",
    "w_reg = np.linalg.pinv(Z.transpose() @ Z + lamb * np.eye(Z.shape[1]) ) @ Z.transpose() @ labels_train\n",
    "y_pred = np.sign(np.dot(Z, w_reg))\n",
    "acc_train = accuracy_score(labels_train, y_pred)\n",
    "\n",
    "# test error\n",
    "y_pred_test = np.sign(np.dot(feat_tfm_test, w_reg))\n",
    "acc_test = accuracy_score(labels_test, y_pred_test)\n",
    "\n",
    "print(f\"Accuracy on training set: {acc_train}\")\n",
    "print(f\"Accuracy on test set: {acc_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
